{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dot Product\n",
    "\n",
    "Write a function `matrix_multiply(A, B)` using for loops, `+` and `*` that takes in two matrices (can be list of lists, or 2d numpy array) and returns their dot product (matrix multiplication). It should work with column vectors ($k \\times 1$ dimensions) and row vectors ($1 \\times k$) normally.\n",
    "\n",
    "\n",
    "```import numpy as np\n",
    "\n",
    "A = [\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "]\n",
    "\n",
    "B = [\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "]\n",
    "\n",
    "matrix_multiply(A,B)\n",
    "\n",
    "RETURNS: \n",
    "[[30, 36, 42],\n",
    " [66, 81, 96]]\n",
    "\n",
    "---------example 2-------------\n",
    "# This is a row vector\n",
    "A = np.array([\n",
    "    [1,2,3]\n",
    "])\n",
    "\n",
    "# This is a column vector\n",
    "B = np.array([\n",
    "    [1],\n",
    "    [4],\n",
    "    [7]\n",
    "])\n",
    "\n",
    "matrix_multiply(A,B)\n",
    "\n",
    "RETURNS:\n",
    "[[30]]\n",
    "\n",
    "```\n",
    "\n",
    "Use `np.dot` to test your output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Matrix Math torture\n",
    "\n",
    "**2.1** Give a 3 examples of non-invertible square matrices that are non-zero\n",
    "\n",
    "**2.2** Explain why the identity matrix $I$ is necessarily a square matrix with only $1$'s on the diagonal (hint: use the dot product from Q1)\n",
    "\n",
    "**2.3** The **trace** is commutative for two matrices so $tr(AB) = tr(BA)$. Give an example where this is false for 3 matrices which can all be multiplied together.\n",
    "\n",
    "**2.4** Give an example of a nonzero $4 \\times 4$ idempotent matrix (where $A \\cdot A = A^2 = A$)\n",
    "\n",
    "**2.5** solve the following system of equations for `x`, `y` and `z` using matrices and `numpy.linalg.solve`\n",
    "\n",
    "$$x \t+ \ty \t+ \tz \t= \t6$$\n",
    "\n",
    "  \t  \t$$2y \t+ \t5z \t= \t−4$$\n",
    "\n",
    "$$2x \t+ \t5y \t− \tz \t= \t27$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Boston regression\n",
    "\n",
    "Using statsmodels and the `boston` dataset, make a regression model to predict house prices. Don't forget to add a constant (intercept) term. Note that statsmodels can take a `pd.DataFrame` as an input for `X`.\n",
    "\n",
    "Report the $R^2$ and coefficients on each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Polynomial features\n",
    "\n",
    "Use polynomial features to improve your regression model in `2.1`. You can use squared and cubic features. Try to find a model that minimizes the `AIC` or `BIC` of your output table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Feature plotting\n",
    "\n",
    "Now that you have a better model, make a regression figure plot for the important feature. The regression plot should be like the ones made at the end of part 3 of this lecture (scatterplot + regression line). It should have the following:\n",
    "\n",
    "- Have the `x` axis be the values from one of your important features. The values should range from the `[min, max]` of the observed values in the dataset.\n",
    "\n",
    "- The y axis on each chart is the target value (house price)\n",
    "\n",
    "- You should have a scatter plot of the datapoints for the feature + the regression line of predicted values on each\n",
    "\n",
    "- If you used non-linearities (squared and/or cube input) the regression curve should be nonlinear as well\n",
    "\n",
    "- When plotting values for a single variable, you can set all the other values to their `mean` or `median` when you put them in your model's prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Multi-feature plotting\n",
    "\n",
    "Make a single matplotlib `figure` object with the same chart as in **2.4** but with 4 charts instead for your 4 most important features. \n",
    "\n",
    "Do not copy-paste code for each feature you visualize in the plot. Extract your code into a function so you can just have something like\n",
    "\n",
    "```python\n",
    "fix, ax1, ax2, ax3, ax4 = plt.subplots((2,2))\n",
    "reg_plot_on_ax(feature_1, ax1)\n",
    "reg_plot_on_ax(feature_2, ax2)\n",
    "reg_plot_on_ax(feature_3, ax3)\n",
    "reg_plot_on_ax(feature_4, ax4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}